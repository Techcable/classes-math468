\documentclass[14pt,letterpaper]{extarticle}
\usepackage[utf8]{inputenc}

% Set margins
% https://tex.stackexchange.com/a/327136
% this should replace use of the 'fullpage' package
\usepackage[
    includehead,
    margin=2.5cm,
    bmargin=2cm,
]{geometry}

\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{verbatim} % This works better than comment for some reason
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{gensymb}
\usepackage{enumitem}
\usepackage{xfrac} % Fractions - https://tex.stackexchange.com/a/230973
\usepackage{xcolor}
% The magic latex drawing thing

\usepackage{tikz}
\usetikzlibrary{shapes}
\usepackage[en-US,showdow]{datetime2}

% Colored hyperlinks:
% https://www.overleaf.com/learn/latex/Hyperlinks
\hypersetup{
    colorlinks=true,
    urlcolor=blue
}

% Setup nice headings
% https://www.overleaf.com/learn/latex/Headers_and_footers
\usepackage{fancyhdr}
\usepackage{titling} % Save title for use in fancyhdr

% Shortcuts
\newcommand*{\bP}{\mathbf{P}}



% Use black tombstone for QED
\renewcommand{\qedsymbol}{$\blacksquare$}

% Important sets
\newcommand*{\C}{\mathbb{C}}
\newcommand*{\R}{\mathbb{R}}
\newcommand*{\Q}{\mathbb{Q}}
\newcommand*{\Z}{\mathbb{Z}}

%
% symbols
%

% name by meaning, not by character
\newcommand{\grad}{\nabla}


% New command for 'partial QED' using white tombstone
\newcommand*{\partialqed}{$\hfill \square$ \\}

\newcommand*{\todo}{{\color{red}\textbf{TODO:}} }

% Increased spaces spacing
\usepackage{setspace} \onehalfspacing

\title{Math 468 - Homework 4}
\author{Nicholas Schlabach (nickninja@arizona.edu)}
\DTMsavedate{titledate}{2026-02-17}
\date{\DTMUsedate{titledate}}

%% Copied from https://tex.stackexchange.com/a/2238
%% Modified by Techcable 9/19/21 to use '[...]' instead of '(...)'
\newenvironment{amatrix}[1]{%
  \left[\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right]
}

\begin{document}
\pagestyle{fancy}
\fancyhead[L]{Nicholas Schlabach}
\fancyhead[C]{\hspace{5mm}\Big(\thetitle{}\Big)}
\fancyhead[R]{{\DTMsetdatestyle{mmddyy}\DTMusedate{titledate}}, Page \thepage}
\fancyfoot{} % no footer
\maketitle
% maketitle automatically sets pagestyle=plain, override this
\thispagestyle{fancy}


\begin{center}
\begin{enumerate}
\item
    \begin{comment}
    There are two ways to approach this problem.
    \vspace{3mm}\\
    Approach 1 (the way in the book):
    \end{comment}
    As demonstrated on page 49, the stationary distribution $\pi$ can be found by solving $\bP\pi=\pi$ subject to the condition $\sum_{i=0}^2 \pi_i=1$.
    \begin{align*}
         .4\pi_0+.4\pi_1+.2\pi_2 & =\pi_0 \\
         .3\pi_0+.4\pi_1+.3\pi_2 &=\pi_1 \\
         .2\pi_2+.4\pi_1+.4\pi_2&=\pi_2  \\
         \pi_0+\pi_1+\pi_2&=1
    \end{align*}
    This can be written as an augmented matrix 
    \[ \begin{amatrix}{3}
        -0.6 & .4 & .2 & 0 \\
        .3 & -0.6 & .3 & 0 \\
        .2 & .4 & -0.6 & 0 \\
        1 & 1 & 1 & 1
        
    \end{amatrix} \]
    Converting to reduced row-echelon form gives the following:
    \[ \begin{amatrix}{3}
        1 & 0 & 0 & 1/3 \\
        0 & 1 & 0 & 1/3 \\
        0 & 0 & 1 & 1/3 \\
        0 & 0 & 0 & 0
        
    \end{amatrix} \]
    This means there is only one solution to the system of equations:
    \[ \pi^*=\langle \frac{1}{3},\frac{1}{3},\frac{1}{3}\rangle \] \\
    But by definition, every stationary distribution $\pi$ must satisfy the requirements $\bP\pi=\pi$ and $\sum_{i=1}^n \pi_i=1$. Since $\pi^*$ is the only distribution that meets these requirements, then $\pi^*$ is the unique stationary distribution for $\bP$. 
    \begin{comment}
    \vspace{3mm}
    Approach 2: \\
    The matrix $\bP$ has eigenvalues $\lambda_1=1, \lambda_2=\frac{1}{5}, \lambda_3=0$. These have associated eigenvectors $v_1=\langle 1,1,1\rangle, v_2=\langle-1,0,1\rangle, v_3=\langle 1,\frac{-3}{2},1\rangle$.
    %  The eigenvalue approach seems problematic since it only gives long-term behavior (steady-state), not necessarily every stationary distribution.
    % This is because stationary distributions can be linear combinations of the bad eigenvectors like v_2=(-1,0,1).
    \end{comment}
\item
    The transition function $\bP$ must satisfy $\sum_{y=0}^\infty\bP(x,y)=1$ for every fixed $x\in S$. In our case, this means that 
    \begin{align}
        \label{constant_seq_converge}
        \sum_{y=0}^\infty \alpha_y=1 & &  y\in S
    \end{align}
    \vspace{3mm} \\
    % I now claim that the distribution $\pi(y)=\alpha_y$ is a stationary distribution for $\bP$.
    A stationary distribution $\pi$ is defined to satisfy $\bP\pi=\pi$, which is equivalent to $\sum_{x=0}^\infty \pi(x)\bP(x,y)=\pi(y)$. Substituting our known transition function $\bP(x,y)=\alpha_y$, we get
    \begin{align}
        \label{problem2_stationary_requirement}
        & \sum_{x=0}^\infty \pi(x)\alpha_y=\pi(y)& y \in S
    \end{align} \\
    % Since it is equivalent to the definition, this condition is both necessary and sufficient.\\
    \vspace{3mm}
    Now I claim that $\pi_0(y)=\alpha_y$ satisfies this requirement: \\
    \begin{tabular}{lll}
        & $\displaystyle{\sum_{x=0}^\infty \pi_0(x)\alpha_y}$ &  \\
        = & $\displaystyle{\sum_{x=0}^\infty \alpha_x\alpha_y}$  \hspace{30mm} & [def. of $\pi_0$] \\
        = & $\displaystyle{\alpha_y\big(\sum_{x=0}^\infty \alpha_x\big)}$ & [since  \eqref{constant_seq_converge} converges and $\alpha_y$ is constant] \\
        = & $\alpha_y$ & [using \eqref{constant_seq_converge}] 
    \end{tabular} \\
    Since $\pi_0(y)=\alpha_y$ and $y \in S$ is arbitrary,  this proves that $\pi_y$ satisfies \eqref{problem2_stationary_requirement}, making it a stationary distribution of $\bP$. \\
    \vspace{3mm}
    Now to prove uniqueness: Assume that $\pi$ is an arbitrary stationary distribution of $\bP$ (not necessarily $\pi_0$). \\
    Because $\pi$ is a probability distribution we know $\sum_{x=0}^\infty \pi(x)=1$. Furthermore, since $\pi$ is a stationary distribution we know it satisfies \eqref{problem2_stationary_requirement}.
    Because $\sum\pi(x)$ is convergent, we can factor out $\alpha_y$ from \eqref{problem2_stationary_requirement} and get
        \begin{align}
        \label{problem2_stationary_arbitrary_dist}
        \pi(y)=\sum_{x=0}^\infty \pi(x)\alpha_y=\alpha_y\Big(\sum_{x=0}^\infty \pi(x)\Big)
     \end{align}
     Using the fact $\sum_{x=0}^\infty \pi(x)=1$, \eqref{problem2_stationary_arbitrary_dist} becomes $\pi(y)=\alpha_y$. This means that $\pi=\pi_0$ from above. 
    We have not assumed anything beyond the fact that $\pi$ is a stationary distribution of $\bP$, so this proves that $\pi_0$ is the unique stationary distribution for $\bP$. 
     % We know that $\sum_{x=0}^\infty \pi(x)=1$ converges since $\pi$ is a probability distribution. This means that $\alpha_y$ can be factored out of \eqref{p2_stationary_cond1} to get
    % The Markov chain must satisfy $\sum_{y\in S}^\infty \bP(x,y)=\sum_{y=0}^\infty \alpha_y=1$ for every $x \in S$. So 

\item
    Assume that $\pi$ is a stationary distribution, that $x$ leads to $y$, and that $\pi(x)>0$.
    The fact $x\to y$ means that $P^n(x,y)>0$ for some $n \in \mathbb{Z}^+$.  \\
     Using equation (3) from page 46, we get $ \sum_{a \in S}\pi(a)\bP^m(a,b)=\pi (b)$ for every $m>0,b \in S$. We know $\pi(x)>0$ by assumption and $\bP^n(x,y)> 0$ since $x\to y$. This means that $\pi(x)\bP^n(x,y)>0$ is positive. Since all other terms of the sum are nonnegative, this means that $\pi(y)>0$ is also positive. \qed
\item
    \begin{comment}
    Based on the discussion in section 1.7 we get $r_x=0$ and the following transition function:
    \[ \bP(x,y)=\begin{cases}
        1-p & y=x-1 \\
        p & y=x+1 \\
        0 & \text{otherwise}
    \end{cases} \] 
    \end{comment}
    According to page 52 of the book, a birth-death chain has a stationary distribution iff the series in equation (11) converges. Using the known values of $p_0=1$ and $0<p_x<1$, equation (11) in the book becomes
    \[ S_1:=\sum_{x=1}^\infty\frac{p_0\dots p_{x-1}}{q_1\dots q_x}=\sum_{x=1}^\infty\frac{p^{x-1}}{(1-p)^x}=\frac{1}{p}\sum_{x=1}^\infty(\frac{p}{1-p})^x \]
    Now this geometric series converges iff $|\frac{p}{1-p}|<1$. Since both $p,1-p$ are positive, we can drop the absolute values and rearrange to get the equivalent condition $p<1-p$ or $p<1/2$. This means that the equation has a stationary distribution iff $p<1/2$. \\
    Let $r:=\frac{p}{1-p}$.  For the remainder of the problem, assume that $p<1/2$  $0<r<1$, so we can find the equilibrium solution $\pi$. Using the formula for the sum of a geometric series starting at $x=1$ we can compute the sum $S_1=\frac{1}{p}\big(\frac{r}{1-r}\big)=\frac{1}{1-2p}$.  \\
    Now, as established in class on Feb. 19th and in the book on page 51, we get the recurrence relation $\pi(y+1)=\frac{p_y}{q_{y+1}}\pi(y)$. Expanding this gives equation (8) on page 51, which can be significantly simplified using the fact that $p_x=p, q_x=1-p$ are independent of $x\ge 1$:
    \begin{align}
    \label{pix_product}
 \pi(x)= &\frac{p_0\dots p_{x-1}}{q_1\dots q_x}\pi(0)=\frac{p^{x-1}}{(1-p)^x}\pi(0)=\frac{1}{p}r^x\pi(0) & x\ge 1
    \end{align}
    We know that $\sum_{x=0}^n \pi(x)=1$ because $\pi$ forms a probability distribution. Combining this condition with \eqref{pix_product} and factoring out $\pi(0)$ we get
    \begin{align}
        \label{normalization_cond1}
        1=\sum_{x=0}^n\pi(x)=\pi(0)+\sum_{x=1}^n\frac{1}{p}r^x\pi(0)=\pi(0)\Big(1+\sum_{x=1}^n\frac{1}{p}r^x\Big)
    \end{align}
    The sum in \eqref{normalization_cond1} is equal to $S_1$, whose value we have already computed
    \begin{align}
        1=\pi(0)\big(1+S_1\big)=\pi(0)\big(1+\frac{1}{1-2p}\big)=\pi(0)\big(\frac{2-2p}{1-2p})
    \end{align}
    This allows us to determine the value of $\pi(0)=\frac{1-2p}{2-2p}$, which in turn allows us to compute all the other states using \eqref{pix_product}:
    \[ \pi(0)=\frac{1-2p}{2-2p}, \hspace{5mm}\pi(x)=\big(\frac{2}{1-2p}\big)r^{x-1} \text{ if }x\ge 1 \]
    Along with the condition $p<\frac{1}{2}$, this gives the final answer.
\end{enumerate}
\end{center}
\end{document}